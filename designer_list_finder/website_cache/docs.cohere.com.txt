The Cohere Platform





































































































































































Jump to ContentGuides and ConceptsAPI ReferenceRelease NotesApplication ExamplesLLMUDashboardDocumentationPlaygroundCommunityLog InDashboardDocumentationPlaygroundCommunityLog InGuides and ConceptsAPI ReferenceRelease NotesApplication ExamplesLLMUSearchGet StartedThe Cohere PlatformIntroduction to Large Language ModelsPlayground OverviewQuickstart TutorialsGoing LiveIntegrationsAmazon SagemakerLearnKey ConceptsEmbeddingsPrompt EngineeringTokensGenerationCommand NightlyLikelihoodNumber of GenerationsTemperatureTop-k & Top-pCustom ModelsTraining Custom ModelsComparing Baseline and Custom ModelsTraining a Generative ModelTraining a Representation ModelTroubleshooting a Custom ModelCustom Model MetricsCustom Models with Cohere's SDKCustom Representative Models with Cohere's SDKCustom Generative Models with Cohere's SDKCustom Rerank Models with Cohere's SDKMultilingual Embed ModelsLanguage DetectionMultilingual Semantic SearchCustomer Feedback AggregationCross-Lingual Content ModerationSupported LanguagesRerankingReranking Best PracticesGenerating FeedbackIntroductory GuidesSemantic SearchContent ModerationEntity ExtractionText ClassificationText Classification (Classify)Text Classification (Embed)Co.summarize (Beta)Co.rerank (Beta)Amazon SageMaker Setup GuideResponsible UseOverviewUsage GuidelinesModel LimitationsData StatementModelsSecurityEnvironmental ImpactLLM UniversityWelcome to LLM University!Structure of the CourseYour InstructorsDiscord and CommunityBrief intro: What is NLP and LLMs?Module 1: What are Large Language Models?Text EmbeddingsSimilarity Between Words and SentencesThe Attention MechanismTransformer ModelsSemantic SearchConclusion - Large Language ModelsModule 2: Text RepresentationClassification ModelsClassification Evaluation MetricsSetting upThe Classify EndpointThe Embed EndpointVisualizing DataSemantic Search Using EmbeddingsClustering Using EmbeddingsClassification Using EmbeddingsCreating Custom Representation ModelsA Deeper Dive Into Semantic SearchTopic ModelingMultilingual Semantic SearchMultilingual Sentiment AnalysisConclusion - Text RepresentationModule 3: Text GenerationWhat is Generative AI?Prompt EngineeringUse Case IdeationThe Generate EndpointCreating Custom Generative ModelsChaining PromptsCohere's Command ModelConclusion - Text GenerationModule 4: DeploymentDeploying with StreamlitDeploying with DatabuttonDeploying with Amazon SageMakerDeploying with FastAPIDeploying on Google Sheets with Google Apps ScriptDeploying as a Chrome ExtensionConclusionAppendix 1: NLP and ML FundamentalsHistory of NLPApplications of NLPText Pre-Processing in NLPHow to Convert Text Into VectorsPast Machine-Learning Methods of NLPHow to Build a ClassifierHow to Evaluate a ClassifierConclusion - NLPAppendix 2: Building AppsApp ExamplesThe Cohere PlatformSuggest EditsCohere offers an API to add cutting-edge language processing to any system. Cohere trains massive language models and puts them behind a simple API. Moreover, through training, users can create massive models customized to their use case and trained on their data. This way, Cohere handles the complexities of collecting massive amounts of text data, the ever evolving neural network architectures, distributed training, and serving models around the clock.
Cohere offers access to both generation models (through the generate endpoint) and
representation models (through the embed endpoint which returns an embedding vector for the input text).
Two major categories of large language models are generative language models (like GPT2 and GPT3) and representation language models (like BERT). Cohere offers variants of both types.
Use Cases
Here are a few examples of language understanding systems that can be built on top of large language models.
Summarize
Large language models present a breakthrough in text generation. For the first time in history, we have software programs that can write text that sounds like itâ€™s written by humans. These capabilities open doors to use cases like summarization or paraphrasing.
Language models can be instructed to generate useful summaries or paraphrases of input text by guiding them using a task description in the prompt.
A summarization prompt in the Cohere playground shows this output (in bold):
  Example summarization prompt and generation. Stop sequence is specified as the period to limit the output to one sentence.
Large language models can be adapted to new tasks with impressive speed. For tasks which appear in the training data (i.e. documents on the web), language models can successfully summarize text without being shown any examples at all.
Two strategies you can experiment with generative language models are prompt engineering and training (which creates a custom model based on your dataset).
Summarization uses the Co.summarize endpoint.
ðŸ“˜New to Cohere?Get Started now and get unprecedented access to world-class Generation and Representation models with billions of parameters.
Classify
Classification is one of the most common use cases in language processing. Building systems on top of language models can automate language-based tasks and save time and energy.
Developers can build classifiers on top of Cohereâ€™s language models. These classifiers can automate language tasks and workflows.
There's more than one way to build a classifier on top of Cohere's language models. It's worth experimenting to see which method works best for your use case. The simpler methods can get you quick results, while the more advanced methods need more data and will lead to better results.
On the simpler side are methods like using the Classify endpoint for classification. More industrial-grade classifiers can be built by fitting a classifier on top of the embed endpoint (see: Embedding endpoint for classification).
Semantic Similarity
Think of how many repeated questions have to be answered by a customer service agent every day. Language models are capable of judging text similarity and determining if an incoming question is similar to questions already answered in the FAQ section.
A similarity score can be computed through our embeddings by calculating the
cosine similarity of two embeddings.
There are multiple things your system can do once it receives the similarity scores â€” one possible next action is to simply show the answer to the most similar question (if above a certain similarity threshold). Another possible next action is to make that suggestion to a customer service agent.Updated about 1 month ago Table of Contents

Use Cases

Summarize
Classify
Semantic Similarity




















































































