PyTorch Lightning Developer BlogOpen in appSign upSign InWriteSign upSign InPyTorch Lightning Developer Blog605 FollowersFollowHomeAboutGrid.aiSkaftenicki¬∑Dec 5, 2022TorchMetrics v0.11 ‚Äî Multimodal and nominalWe are happy to announce that Torchmetrics v0.11 is now publicly available. In Torchmetrics v0.11 we have primarily focused on the cleanup of the large classification refactor from v0.10 and adding new metrics. With v0.11 are crossing 90+ metrics in Torchmetrics nearing the milestone of having 100+ metrics. Classification refactor First, we‚Ä¶Pytorch5 min readPytorch5 min readSean Narenthiran¬∑Nov 29, 2022Lightning Transformers 0.2 ‚Äî New ü§óTasks, Community Features, and Big Model Training & InferencePairing ü§ó Transformers and Lightning has become increasingly popular, leveraging Lightning to hide away the boilerplate of your training code, whilst training using the extensive models and datasets library that Transformers provides. Today we‚Äôre announcing Lightning Transformers 0.2 packed with new features, including the new Vision Transformers Image Classification Task‚Ä¶Machine Learning3 min readMachine Learning3 min readSkaftenicki¬∑Oct 17, 2022TorchMetrics v0.10 ‚Äî Large changes to classificationsTorchMetrics v0.10 is now out, significantly changing the whole classification package. This blog post will go over the reasons why the classification package needs to be refactored, what it means for our end users, and finally, what benefits it gives. ‚Ä¶Pytorch7 min readPytorch7 min readSkaftenicki¬∑May 31, 2022TorchMetrics v0.9 ‚Äî Faster forwardTorchMetrics v0.9 is now out, and it brings significant changes to how the forward method works. This blog post goes over these improvements and how they affect both users of TorchMetrics and users that implement custom metrics. TorchMetrics v0.9 also includes several new metrics and bug fixes. ‚Äî  TL;DR: If you only use metrics from TorchMetrics, you do not need to change anything in your code. If you implement your own metrics, you need to set one new class property.Pytorch5 min readPytorch5 min readSunil Srinivasa¬∑May 20, 2022Turbocharge Multi-Agent Reinforcement Learning with WarpDrive and PyTorch LightningAuthors: Sunil Srinivasa, Tian Lan, Huan Wang, Stephan Zheng, and Donald Rose Reinforcement Learning: Agents Learn by Maximizing Rewards Reinforcement Learning (RL) is a subfield of Machine Learning (ML) that deals with how intelligent agents should act in an environment when they wish to maximize a reward. ‚Ä¶8 min read8 min readCarlos Mochol√≠¬∑May 10, 2022PyTorch Lightning 1.6: Support Intel‚Äôs Habana Accelerator, New efficient DDP strategy (Bagua), Manual Fault-tolerance, Stability, and Reliability.PyTorch Lightning 1.6 is the work of 99 contributors who have worked on features, bug fixes, and documentation for a total of over 750 commits since 1.5. This is our most active release yet. Here are some highlights: Introducing Intel‚Äôs Habana Accelerator Check out our previous post about leveraging Intel‚Äôs new hardware with PyTorch‚Ä¶7 min read7 min readKaushik Bokka¬∑May 5, 2022Supercharge your training with zero code changes using Intel‚Äôs Habana Accelerator ‚ö°Ô∏èWe recently added support for Habana‚Äôs Gaudi AI Processors, which can be used to accelerate deep learning training workloads. We also covered the benefits of using Habana and how to leverage the Habana Accelerator with PyTorch Lightning on a livestream: What is the Habana Gaudi AI Processor? ü§î Habana Gaudi was designed from the ground up to‚Ä¶Deep Learning4 min readDeep Learning4 min readPyTorch Lightning team¬∑Apr 19, 2022Experiment with Billion-Parameter Models Faster using DeepSpeed and Meta TensorsPyTorch‚Äôs Meta Tensors can save you huge amounts of time. PyTorch Lightning, together with DeepSpeed and just a single line of code, allows you to train large, billion-parameter models even faster. ‚Äî  PyTorch Lighting is a lightweight PyTorch wrapper for high-performance AI research. PyTorch Lightning provides true flexibility by reducing the engineering boilerplate and resources required to implement state-of-the-art AI. ‚Ä¶Pytorch4 min readPytorch4 min readSkaftenicki¬∑Apr 14, 2022TorchMetrics v0.8 ‚Äî Paper, Faster collection, and more metrics!We are excited to announce that TorchMetrics v0.8 is now available. This release includes several new metrics in the classification and image domains as well as performance improvements for those working with metrics collections. ‚Äî  Release Faster collection and more metrics! ¬∑ PyTorchLightning/metrics
We are excited to announce that TorchMetrics v0.8 is now available. The release includes several new metrics in the‚Ä¶github.comMetrics5 min readMetrics5 min readCarlos Mochol√≠¬∑Apr 12, 2022Bagua: A new, efficient distributed training strategy available in PyTorch LightningWe‚Äôve added support for a new distributed training strategy in collaboration with the Bagua team. ‚Äî  We also covered the benefits of this training strategy in a live stream: What is Bagua? BaguaSys/Bagua is a deep learning acceleration framework for PyTorch developed by AI platform@Kuaishou Technology and DS3 Lab@ETH. Bagua supports multiple, advanced distributed training algorithms with state-of-the-art system relaxation techniques. These include quantization, decentralization, and communication delay.Pytorch3 min readPytorch3 min readPyTorch Lightning is a lightweight machine learning framework that handles most of the engineering work, leaving you to focus on the science. Check it out: pytorchlightning.aiFollowConnect with PyTorch Lightning Developer BlogEditorsAaron (Ari) Bornstein<Microsoft Open Source Engineer> I am an AI enthusiast with a passion for engaging with new technologies, history, and computational medicine.FollowThomas ChatonFollow„Ç§„É´„Ç´ BorovecI have been working in ML and DS for a while in a few IT companies. I enjoy exploring interesting world problems and solving them with SOTA techniques‚Ä¶FollowSee allHelpStatusWritersBlogCareersPrivacyTermsAboutText to speechTeams




































